<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Explorer</title>
  
  
  <link href="https://miaochenlu.github.io/atom.xml" rel="self"/>
  
  <link href="https://miaochenlu.github.io/"/>
  <updated>2021-10-13T05:28:27.366Z</updated>
  <id>https://miaochenlu.github.io/</id>
  
  <author>
    <name>Chenlu Miao</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hello World</title>
    <link href="https://miaochenlu.github.io/2021/10/13/hello-world/"/>
    <id>https://miaochenlu.github.io/2021/10/13/hello-world/</id>
    <published>2021-10-13T03:55:30.516Z</published>
    <updated>2021-10-13T05:28:27.366Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start">Quick Start</h2><h3 id="Create-a-new-post">Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server">Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files">Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites">Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello world&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>a</mi><mo>&gt;</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">a &gt; b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathdefault">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">b</span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo fence="true">[</mo><mo fence="true">]</mo></mrow><annotation encoding="application/x-tex">\left[ \right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">[</span><span class="mclose delimcenter" style="top:0em;">]</span></span></span></span></span></span></p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>a</mi><mo>&gt;</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">a&gt;b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathdefault">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">b</span></span></span></span></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; for</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>MapReduce详解</title>
    <link href="https://miaochenlu.github.io/2021/10/13/mapreduce/"/>
    <id>https://miaochenlu.github.io/2021/10/13/mapreduce/</id>
    <published>2021-10-13T02:19:33.000Z</published>
    <updated>2021-10-13T05:55:13.472Z</updated>
    
    <content type="html"><![CDATA[<h1>为什么会产生MapReduce</h1><p>面对大量的数据，需要充分利用大量机器的运算资源来提高效率</p><p>但是，如何利用大量机器进行并行计算，如何分配数据到各个机器上，如何处理failure，在分布式的情况下都非常复杂</p><p>而MapReduce就是用来应对这种复杂性的抽象计算模型 。这个模型可以将大型数据处理任务分解成很多单个的、可以在服务器集群中并行执行的任务，而这些任务的计算结果可以合并在一起来计算最终的结果</p><p>MapReduce主要有两个过程：Map和Reduce</p><h1>Map过程</h1><p>Map过程将原始数据转换成key/value pairs</p><p>以最简单的word count程序为例，这个程序的功能是计算文件中每个单词的出现次数</p><p>Map阶段， Map函数接收一个输入文件，对文件中的每一个单词输出一个键值对 <code>(word, occurrence)</code>, 这里每个单词出现就记occurrence为1，所以这里的键值对为<code>(word, 1)</code></p><p>由此，我们将一个输入文件map到了一个key/value数组</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">map</span>(String key, String value):</span><br><span class="line">    <span class="comment"># key: document name</span></span><br><span class="line">    <span class="comment"># value: document contents</span></span><br><span class="line"><span class="keyword">for</span> each word w <span class="keyword">in</span> value:</span><br><span class="line">        EmitIntermediate(w, <span class="string">&quot;1&quot;</span>)</span><br></pre></td></tr></table></figure><img src="/2021/10/13/mapreduce/1627540264381-90ad80dd-c734-47fa-b888-9be5da2c89ed.svg" alt="img" style="zoom:80%;"><h1>Reduce</h1><p>对于map输出的key/value pairs, Reduce是将相同key值的value合并的过程</p><p>在word count程序中，map输出了<code>(word, 1)</code>键值对，为了计算一个单词出现的总数，需要将key/value pair中key相同的value加起来</p><p>每一个reducer处理特定的word。相同word的key/value pair进入同一个reducer, 统计计数</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">reduce(String key, Iterator values):</span><br><span class="line">    <span class="comment"># key: a word</span></span><br><span class="line">    <span class="comment"># values: a list of counts</span></span><br><span class="line">    <span class="built_in">int</span> result = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> each v <span class="keyword">in</span> values:</span><br><span class="line">        result += ParseInt(v)</span><br><span class="line">    Emit(AsString(result))</span><br></pre></td></tr></table></figure><img src="http://localhost/mapreduce/1627562526133-9c1a3c01-2f06-44bb-bf26-187096c1f137.svg" alt="img" style="zoom:100%;"><h1>More Complex</h1><p>MapReduce实际细节中还包含更复杂的partition, shuffle, merge过程</p><img src="/2021/10/13/mapreduce/../../Desktop/miaochenlu.github.io/source/_posts/mapreduce/1627562551985-06cf6168-36f2-4bec-b9d6-17fd8ba834e1.svg" alt="img" style="zoom:100%;"><h2 id="Map端Shuffle">Map端Shuffle</h2><h3 id="整体思路">整体思路</h3><p>可以预期，map过后，我们会得到无序的键值对，如下所示。每一个key的数据都可能分散在各个位置</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a, <span class="number">1</span></span><br><span class="line">b, <span class="number">1</span></span><br><span class="line">a, <span class="number">1</span></span><br><span class="line">c, <span class="number">1</span></span><br><span class="line">a, <span class="number">1</span></span><br><span class="line">b, <span class="number">1</span></span><br><span class="line">c, <span class="number">1</span></span><br></pre></td></tr></table></figure><p>然而reducer是术业有专攻的，在reduce过程中，相同key值的数据需要被送到同一个reducer</p><p>若要去一个一个文件全局搜索去寻找对应的key值，效率必然是低下的</p><p>因此，我们希望map输出是聚集在一起的, 像下面这样。如此一来，寻找对应的key值就会很快</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a, <span class="number">1</span></span><br><span class="line">a, <span class="number">1</span></span><br><span class="line">a, <span class="number">1</span></span><br><span class="line">b, <span class="number">1</span></span><br><span class="line">b, <span class="number">1</span></span><br><span class="line">c, <span class="number">1</span></span><br><span class="line">c, <span class="number">1</span></span><br></pre></td></tr></table></figure><p>当然，为了能够更快定位到reducer需要的key值部分，加上索引是更快捷的做法</p><p>我的想法是索引和数据在同一文件，如下图</p><img src="/2021/10/13/mapreduce/../../Desktop/miaochenlu.github.io/source/_posts/mapreduce/1627545370364-1e5e6f15-d3a9-45bd-a323-4d3093160436.svg" alt="img" style="zoom:100%;"><p>但似乎一般做法是索引与数据分离，让索引都存在于内存中</p><img src="/2021/10/13/mapreduce/../../Desktop/miaochenlu.github.io/source/_posts/mapreduce/1627548186699-258e23e3-d302-41bb-9c82-4518aa4d2ad3.svg" alt="img" style="zoom:100%;"><p>接下来考虑如何才能让键值相同的数据聚集在一起呢？</p><p>方法1: HashMap</p><p>方法2: Sort</p><p>用这两种方法的都有。sort耗费时间开销大，hashmap耗费空间开销大。这里我们基于sort</p><h3 id="Partition">Partition</h3><p>Map端输出是发送给N个Reducer做Reduce工作</p><p>因此，我们需要将Map端的文件映射到Reducer, 相同键值的映射到同一个Reducer, 且尽量保证其负载均衡</p><p>这是做Partition的目的。</p><p>在Partition方式上，我们为key/value pair增加一个partition属性，这个partition属性是对key计算hash计算得到的，为了一个partition对应一个reducer, 在计算hash时对reducer的数量取模</p><p>partition值为几，该key/value pair就会进入第几个reducer</p><p>hash得到的partition能够保证相同键值的数据映射到同一个partition, 也就是reducer，但是一个partition不能保证只有一种键值</p><h3 id="Collector">Collector</h3><p>一个环状数组，最大限度地利用内存</p><p>内存占用到一定程度，就会触发spill, 写入磁盘</p><p>环状数组存储两类数据</p><ul><li><p>原始的Key-Value数据</p></li><li><p>Metadata数据：（注意Key, Value的大小不是固定的，所以需要存长度）</p></li><li><ul><li>Key的起始位置</li><li>Value的起始位置</li></ul></li><li><ul><li>Value的长度</li><li>Partition</li></ul></li></ul><p>选定Equator, 这两类数据以Equator为起点，向两个相反的方向增长</p><p>当数据达到一定阈值(比如80%时），Key-Value数据要写入磁盘。</p><p>此时，空余的20%缓冲区可以用来接收新来的数据，此前，要重新选定Equator</p><img src="/2021/10/13/mapreduce/../../Desktop/miaochenlu.github.io/source/_posts/mapreduce/1627551065742-e5cf8d36-5e74-41e8-967b-895a09c93a8f.svg" alt="img" style="zoom:100%;"><h3 id="Sort">Sort</h3><p>Spill触发后，在写入磁盘前，将Collector中的数据按照partition和key对数据进行升序排序</p><p>按照Partition排序是为了让相同partition数据的聚集在一起，但是一个partition不是只有一种键值，因此再对键值排序保证了相同键值的数据聚集在一起</p><p>注意，不对Key-Value数据排序，而是对<strong>Metadata</strong>排序</p><ul><li>读取Metadata, 将Metadata数据按照Partition进行排序</li><li>在同一Partition中，读取Metadata对应的Key值，按照Key值再次排序</li></ul><h3 id="Combine-自定义优化步骤">Combine(自定义优化步骤)</h3><p>将Map输出的key/value pair进行合并，是一个本地reduce过程</p><p>比如word count程序，map输出</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a, <span class="number">1</span></span><br><span class="line">a, <span class="number">1</span></span><br><span class="line">a, <span class="number">1</span></span><br></pre></td></tr></table></figure><p>我们就可以定义一个combine程序，将其合并为<code>(a, 3)</code>再发送给reducer</p><h3 id="Spill">Spill</h3><ul><li><p>创建磁盘文件</p></li><li><p>将Collector中的数据按照Metadata排序顺序依次写入文件，写磁盘的时候数据会进行压缩</p></li><li><p>同时会创建索引文件。索引文件对每一个partition会记录一个三元组 <code>(起始位置，原始数据长度，压缩后的数据长度)</code>, 在这个文件中也会存储crc32的校验数据</p></li></ul><h3 id="Merge">Merge</h3><p>在数据量大的时候，有可能进行好几次spill, 产生了多个数据文件和索引文件，这个时候就需要将文件合并</p><p>如何获得Spill文件呢—&gt;扫描本地目录, 然后把文件路径存到数据里面，索引文件同理</p><p>对于1个Partition，扫描索引文件，得到k个数据文件，做一个k路外部排序</p><p>如果设置了combiner, Merge时也会调用combiner合并key相同的数据</p><p>Map Shuffle整体结构</p><img src="/2021/10/13/mapreduce/../../Desktop/miaochenlu.github.io/source/_posts/mapreduce/1627562412124-a77ba37a-3bb2-49cf-bfb3-6b63a2c272d0.svg" alt="img" style="zoom:80%;"><h1>Reduce Shuffle</h1><p>Reduce Shuffle主要有两个过程：</p><ul><li>Copy</li><li>Merge</li></ul><h2 id="Copy">Copy</h2><p>将Map得到的数据copy到本地</p><h2 id="Merge-2">Merge</h2><p>做一个数据的外部排序</p><h1>Reference</h1><p>[1] <a href="https://plandocheckaction.github.io/2020/09/07/BigData14-MapReduceSuffle/">环形缓冲区</a></p><p>[2] <a href="https://www.cnblogs.com/edisonchou/p/4298423.html">Hadoop中的压缩</a></p><p>[3] <a href="https://stackoverflow.com/questions/5100252/external-sorting">External Sorting</a></p><p>[4] <a href="https://zhuanlan.zhihu.com/p/55884610">MapReduce计算框架</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;为什么会产生MapReduce&lt;/h1&gt;
&lt;p&gt;面对大量的数据，需要充分利用大量机器的运算资源来提高效率&lt;/p&gt;
&lt;p&gt;但是，如何利用大量机器进行并行计算，如何分配数据到各个机器上，如何处理failure，在分布式的情况下都非常复杂&lt;/p&gt;
&lt;p&gt;而MapReduce就是</summary>
      
    
    
    
    
    <category term="分布式系统" scheme="https://miaochenlu.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
</feed>
